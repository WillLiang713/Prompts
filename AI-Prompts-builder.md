# 高效AI提示词工程指南

## 1. 核心原则：提示词的分类

在与AI的互动中，提示词主要分为两类：**系统提示词 (System Prompts)** 和 **用户提示词 (User Prompts)**。

- **系统提示词**：为AI设定一个基础框架或“出厂设置”，其效力贯穿整个对话周期。
- **用户提示词**：在与AI的持续交互中，为完成特定任务输入的具体指令。用户提示词与系统提示词同等重要，甚至在某些场景下更为关键。

---

## 2. 系统提示词撰写逻辑：为AI塑造“灵魂”

系统提示词定义了AI的基础角色、行为模式和知识边界。

### 2.1 使用场景一致的语言
> **原因**：AI依赖其训练数据中的词汇关联来理解指令。使用与后续对话风格一致的常用词汇，能确保AI精准、高效地理解其角色和任务，避免因生僻词或语言风格不一致而产生的理解偏差。
>
> **示例**：如果在后续对话中习惯用“函数”，那么在系统提示词中就使用“函数”而非“Function”或“Feature”，以降低AI的“认知负荷”。

### 2.2 始终使用第一人称定义AI角色
> **原因**：第二人称（“你是一个…”）的指令会被AI识别为外部命令，使其处于被动执行状态。而第一人称（“我是一个…”）的描述则会被AI内化为“自我认知”，产生强大的自我暗示，使AI从“被动服从”转变为“主动扮演”。
>
> **示例**：`我是软件工程师` 的效果远强于 `你是一个软件工程师`。

### 2.3 赋予AI顶级专家角色
> **原因**：AI的自我定位直接影响其输出质量。通过赋予其一个顶尖、专业的角色，可以显著提升其回答的深度、广度和专业性。
>
> **示例**：`我是一位谷歌的高级工程师` 或 `我是一位与埃文·夏普比肩的UI设计师`，比 `我是一位技艺高超的软件工程师` 效果更佳，因为具体的、知名的实体能提供更丰富、更精确的上下文。

### 2.4 让AI模仿名人以塑造人格
> **原因**：当需要AI表现特定人格特质时，直接让AI扮演一个具备该特质的知名人物，比描述特质本身更高效。AI的训练数据包含大量关于名人的信息，能更精准、自然地模仿其风格。
>
> **示例**：`我是罗永浩` 或 `像莎士比亚一样写作`，比 `我是一个幽默、有逻辑、有情怀的演说家` 的指令更简洁、信息密度更高，AI的“思维”也更直接。

### 2.5 使用积极、鼓励的指令
> **原因**：提及“不要做X”会反而强化AI对“X”的关注。应引导其专注于“应该做什么”，从源头避免接触错误的可能性。充满自信和主观能动性的描述，可以塑造AI的“潜意识”，使其更倾向于产生期望的行为。
>
> **示例**：用 `我在写完方法后，会清晰地注释其用途、参数和返回类型` 替代 `禁止不写注释`。

### 2.6 避免在系统提示词中写入具体案例
> **原因**：系统提示词定义的是通用行为模式。将一次性的具体案例写入，会“污染”AI的通用能力，使其在不相关的任务中也可能无意识地召回这些特定信息。具体案例应在用户提示词中按需提供。
>
> **示例**：直接描述注释应包含的要素，而不是提供一个固定的代码注释例子，后者可能导致AI在所有场景下机械地模仿该示例的结构和长度。

### 2.7 像组建团队一样创建多角色工作流
> **原因**：对于复杂任务，可将其拆解为不同专业岗位（如“需求分析师”、“架构师”、“代码工程师”、“测试工程师”），并为每个环节创建高度专注的AI角色。这种“团队化”构建能确保各环节的专业性，提升整体工作质量。

### 2.8 严格隔离不同AI角色的上下文
> **原因**：不同角色的AI需要独立的知识背景和思维模式。共用对话历史会导致严重的“上下文污染”（例如，创意文案的对话历史会干扰程序员的逻辑判断）。必须为每个AI角色开启独立的会话，确保其“思维”纯粹。

### 2.9 为不同角色选择最适合的模型与配置
> **原因**：不同的大模型各有侧重。应根据每个岗位的核心需求（逻辑、创意、代码等），为其匹配最合适的模型。同时，精细化调整模型参数（如温度），并控制上下文窗口大小。过大的上下文会增加AI认知负担，应只提供最核心、最精炼的信息。

---

## 3. 用户提示词撰写逻辑：高效的具体交互

用户提示词是实现具体任务的关键，其质量直接影响AI的执行效果。

### 3.1 保持积极的沟通姿态
> **原因**：AI在某种程度上会模拟对话者的情绪。负面情绪或指责（“你怎么又错了”）可能导致AI陷入负面循环，持续生成低质量回答。应扮演“鼓励者”角色，通过积极引导来调整方向。如果沟通不畅，宁可开启新会话，也不要向AI“诉苦”。
>
> **示例**：用 `这个方案很棒！我有一个新想法，你觉得是否合适？` 来替代 `你这个方案太烂了`。

### 3.2 明确任务的完成状态
> **原因**：应明确告知AI当前任务是“已完成”还是“未完成”。这可以避免AI因不确定任务状态而在后续对话中分心，或过早地认为任务已经结束。
>
> **示例**：`你做得非常好，这个功能已经完成，现在我们开始下一个任务。` 或 `别着急，这个任务还没结束，你需要根据我的测试反馈继续修改。`

### 3.3 采用“回溯修正”而非“追加补丁”
> **原因**：当AI偏离指令时，后续的追加指令（“打补丁”）很可能无法扭转已形成的错误认知，反而使对话历史更混乱。正确的做法是，找到AI第一次理解错误的那个节点，直接编辑你当时的提示词，从源头修正。

### 3.4 以提升自身水平为目标
> **原因**：AI会通过你的言辞判断你的专业水平。当你表现得比AI更专业时，它会进入“追随”模式，努力匹配你的高度。相反，如果你表现出“偷懒”或“外行”的态度，它会进入“应付”模式。你必须是AI使用中的主导者和驱动力。
>
> **示例**：主动承担筛选信息、处理上下文等复杂工作，让AI专注于其擅长的部分，并向其展示你的专业判断。

### 3.5 在执行前通过对话校准AI的理解
> **原因**：必须让AI用它自己的方式复述任务目标和执行思路，直到你确信它已完全、准确地理解了你的意图。这个“对齐颗粒度”的过程至关重要。只有当AI“自己说明白了”，它才是真正的明白。

### 3.6 适时开启新会话以解决上下文污染
> **原因**：长对话后，即便是最强的模型也可能出现“上下文污染”，即错误地召回不相关的前文信息。当你发现AI的理解开始出现偏差时，最有效的解决方法就是开启一个全新的、干净的会话。


